{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7320b682",
   "metadata": {},
   "source": [
    "# Web Scraping Project By khushi shukla "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e1896",
   "metadata": {},
   "source": [
    "Scrape(Using Beautiful Soup or Selenium) all product details from https://www.amazon.in/s?rh=n%3A6612025031&fs=true&ref=lp_6612025031_sar\n",
    "details needed are Product Name, Price, Rating, Seller Name (If not out of stock)\n",
    "The program should create a CSV file with the above columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c53fbae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs \n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d919a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserting the given url\n",
    "url = 'https://www.amazon.in/s?rh=n%3A6612025031&fs=true&ref=lp_6612025031_sar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "965b8d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the content present in the give URL\n",
    "page=requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32dc6b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking HTTP response \n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92232e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the html code from the page\n",
    "soup = bs(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "600e3f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have given the detailing of product to scrap the content from it\n",
    "lists = soup.find_all('div',class_='a-section a-spacing-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73c0805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is use to create CSV file in which we will store the columns\n",
    "with open(\"C:\\\\Users\\\\nikhi\\\\OneDrive\\\\Desktop\\\\python\\\\Amazon.csv\",'w',encoding='utf8',newline='') as f:\n",
    "    thewriter=writer(f) #created a writer that will write headers in file\n",
    "    header=['Product_name','Price','Rating'] #column names\n",
    "    thewriter.writerow(header)  #writing the headers in the csv file\n",
    "    \n",
    "    for l in lists:\n",
    "        Product_title = l.find('h2',class_=\"a-size-mini a-spacing-none a-color-base s-line-clamp-4\").text #getting products name\n",
    "        Price = l.find('span',class_=\"a-price-whole\").text #getting price of products\n",
    "        Rating = l.find('span',class_=\"a-size-base\").text  #getting Rating of products\n",
    "    \n",
    "        info = [Product_title,Price,Rating]  #making list of things that we have scrap\n",
    "        thewriter.writerow(info)  #storing the name, rating and price of all products in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca2e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
